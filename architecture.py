# -*- coding: utf-8 -*-
"""Architecture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i-_rL5qbFd-Ucg7xw4LhnhaFUkDace1i
"""

class Patches3D(layers.Layer):
    def __init__(self, patch_size, patch_depth):
        super(Patches3D, self).__init__()
        self.patch_size = patch_size
        self.patch_depth = patch_depth

    def call(self, volume):
        batch_size = tf.shape(volume)[0]
        patches = tf.extract_volume_patches(
            volume,
            [1, self.patch_depth, self.patch_size, self.patch_size, 1],
        [1, self.patch_depth, self.patch_size, self.patch_size, 1],
            "VALID",
        )
        # print(patches.shape)
        patch_dims = patches.shape[-1]
        patches = rearrange(patches, 'b t h w c-> b (t h w) c')
        return patches

def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = layers.Dense(units, activation=tf.nn.gelu, kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer)(x)
        x = layers.Dropout(dropout_rate)(x)
    return x

def residual_block(x, filters, conv_num=3, activation="relu"):
    # Shortcut
    s = keras.layers.Conv1D(filters, 1, padding="same", kernel_regularizer=kernel_regularizer,
    activity_regularizer=tf.keras.regularizers.L2(0.01))(x)
    for i in range(conv_num - 1):
        x = keras.layers.Conv1D(filters, 3, padding="same", kernel_regularizer=tf.keras.regularizers.L1(0.01),
    activity_regularizer=activity_regularizer)(x)
        x = keras.layers.Activation(activation)(x)
    x = keras.layers.Conv1D(filters, 3, padding="same", kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer)(x)
    x = keras.layers.Add()([x, s])
    x = keras.layers.Activation(activation)(x)
    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)


def build_model_audio(input_shape):
    inputs = keras.layers.Input(shape=input_shape, name="input")

    x = residual_block(inputs, 64, 2)
    x = keras.layers.BatchNormalization()(x)
    x = residual_block(x, 64, 2)
    x = keras.layers.BatchNormalization()(x)
    x = residual_block(x, 128, 3)
    x = keras.layers.BatchNormalization()(x)
    x = residual_block(x, 256, 3)
    x = keras.layers.BatchNormalization()(x)
    out = residual_block(x, 384, 3)
    x = keras.layers.BatchNormalization()(x)


    

    return keras.models.Model(inputs=inputs, outputs=out)

class AudioFFTLayer(keras.layers.Layer):
    def __init__(self):
        super(AudioFFTLayer, self).__init__()
    
    def call(self, audio):
        fft = tf.signal.fft(
        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)
    )
        fft = tf.expand_dims(fft, axis=-1)

        # Return the absolute value of the first half of the FFT
        # which represents the positive frequencies
        out = tf.math.abs(fft[:, : (audio.shape[1] // 2), :])
        # print(out.shape)
        return out

class MLPMixerLayer(layers.Layer):
    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):
        super(MLPMixerLayer, self).__init__(*args, **kwargs)

        self.mlp1 = keras.Sequential(
            [
                layers.Dense(units=num_patches, kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer),
                tfa.layers.GELU(),
                layers.Dense(units=num_patches, kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer),
                layers.Dropout(rate=dropout_rate),
            ]
        )
        self.mlp2 = keras.Sequential(
            [
                layers.Dense(units=num_patches, kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer),
                tfa.layers.GELU(),
                layers.Dense(units=hidden_units, kernel_regularizer=kernel_regularizer,
    activity_regularizer=activity_regularizer),
                layers.Dropout(rate=dropout_rate),
            ]
        )
        self.normalize = layers.LayerNormalization(epsilon=1e-6)

    def call(self, inputs):
#         print(inputs.shape)
        # Apply layer normalization.
        x = self.normalize(inputs)
        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].
        x_channels = tf.linalg.matrix_transpose(x)
        # Apply mlp1 on each channel independently.
        mlp1_outputs = self.mlp1(x_channels)
        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].
        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)
        # Add skip connection.
        x = mlp1_outputs + inputs
        # Apply layer normalization.
        x_patches = self.normalize(x)
        # Apply mlp2 on each patch independtenly.
        mlp2_outputs = self.mlp2(x_patches)
        # Add skip connection.
        x = x + mlp2_outputs
        return x

audio_model = build_model_audio((1600, 1))

def build_classifier_av_mlp_mixer(positional_encoding=False):
    inputs_audio = layers.Input(shape=(3200))
    inputs_video = layers.Input(shape=(5, 56, 56, 3))
    
    audio_fft = AudioFFTLayer()(inputs_audio)
    x_audio = audio_model(audio_fft)
    patches_video = Resnet3DBuilder.build_resnet_18((5, 56, 56, 3), 10)(inputs_video)
    patches_video = keras.layers.Reshape((-1, 384))(patches_video)
    x_video = layers.Dense(units=embedding_dim)(patches_video)
    
    if positional_encoding:
        positions_video = tf.range(start=0, limit=num_patches, delta=1)
        position_embedding_video = layers.Embedding(
            input_dim=num_patches, output_dim=embedding_dim
        )(positions_video)
        x_video = x_video + position_embedding_video
        positions_audio = tf.range(start=0, limit=num_patches_audio, delta=1)
        position_embedding_audio = layers.Embedding(
            input_dim=num_patches_audio, output_dim=embedding_dim
        )(positions_audio)
        x_audio = x_audio + position_embedding_audio
    x_video = MLPMixerLayer(125, 384, 0.2)(x_video)
    x_audio = MLPMixerLayer(50, 384, 0.2)(x_audio)
    x = layers.Lambda(lambda  x: tf.concat(x, axis=1))((x_video, x_audio))
    x = layers.LayerNormalization()(x)
    for _ in range(num_blocks):
        x = MLPMixerLayer(175, 384, dropout_rate)(x)
    representation = layers.GlobalAveragePooling1D()(x)
    representation = layers.Dropout(rate=dropout_rate)(representation)
    logits = layers.Dense(2, activation='sigmoid')(representation)
    return keras.Model(inputs=[inputs_audio, inputs_video], outputs=logits)

class GCAdamW(tfa.optimizers.AdamW):
    def get_gradients(self, loss, params):

        grads = []
        gradients = super().get_gradients()
        for grad in gradients:
            grad_len = len(grad.shape)
            if grad_len > 1:
                axis = list(range(grad_len - 1))
                grad -= tf.reduce_mean(grad, axis=axis, keep_dims=True)
            grads.append(grad)

        return grads